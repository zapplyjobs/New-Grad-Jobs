# Job Description Fetcher - Quick Reference

**Version:** 2.0.0
**Status:** âœ… Production Ready
**Coverage:** ~90% of all jobs
**Last Updated:** November 13, 2025

---

## ğŸ“– Quick Links

| Document | Purpose |
|----------|---------|
| **[INTEGRATION_COMPLETE.md](INTEGRATION_COMPLETE.md)** | Integration guide and verification checklist |
| **[DESCRIPTION_FETCHER_FINAL_SUMMARY.md](DESCRIPTION_FETCHER_FINAL_SUMMARY.md)** | Complete technical documentation |
| **[jobboard/src/backend/services/descriptionFetchers/README.md](jobboard/src/backend/services/descriptionFetchers/README.md)** | API reference and usage examples |
| **[CHANGELOG.md](CHANGELOG.md)** | Version 2.0.0 release notes |

---

## ğŸš€ What It Does

Automatically fetches full job descriptions from various ATS platforms and adds them to your job postings.

**Before:** Jobs had minimal placeholder descriptions
**After:** Jobs have rich 4,000-6,000 character descriptions with requirements, responsibilities, and salary info

---

## âœ… Platform Coverage

| Platform | Method | Coverage | Success Rate |
|----------|--------|----------|--------------|
| **Greenhouse** | HTTP scraping | ~30-40% | ~95% |
| **Ashby** | JSON-LD extraction | ~10-15% | ~95% |
| **Workday** | Puppeteer | ~40-50% | ~90% |
| **Lever** | Puppeteer | ~5-10% | ~85% |
| **Generic** | Fallback | ~5% | ~70% |
| **Overall** | Hybrid | **~90%+** | **~90%** |

---

## ğŸ“Š How It's Integrated

The description fetcher runs automatically in your job processing workflow:

```
Fetch Jobs â†’ Filter â†’ Deduplicate â†’ [FETCH DESCRIPTIONS] â†’ Write JSON â†’ Post to Discord
                                            â†‘
                                       NEW STEP
```

**Location:** `.github/scripts/job-fetcher/job-processor.js` (lines 315-344)

---

## ğŸ”§ Key Features

### 1. Hybrid Approach
- **Fast HTTP scraping** for Greenhouse & Ashby (2-5 seconds/job)
- **Puppeteer headless browser** for Workday & Lever (8-12 seconds/job)
- **Automatic fallbacks** if primary method fails

### 2. Smart Caching
- **7-day cache** for all fetched descriptions
- **MD5-hashed filenames** for privacy
- **Automatic expiration** cleanup
- **Location:** `.github/data/description-cache/`

### 3. Graceful Degradation
- Jobs still post even if description fetch fails
- Multiple retry attempts with exponential backoff
- Platform-specific fallback strategies

### 4. Detailed Monitoring
```
âœ… Description fetching complete:
   Success: 23/25 (92.0%)
   Failed: 2
   Platforms: greenhouse(8), workday(10), ashby(3)...
```

---

## ğŸ§ª Testing

### Run Test Suite
```bash
# Test all platforms
npm run test:descriptions

# Test integration with workflow
npm run test:integration
```

### Test Individual Platform
```bash
node -e "const {fetchDescription}=require('./jobboard/src/backend/services/descriptionFetchers'); (async()=>{const r=await fetchDescription('YOUR_JOB_URL'); console.log(r);})();"
```

### Check Cache Stats
```bash
node -e "const {cache}=require('./jobboard/src/backend/services/descriptionFetchers'); console.log(cache.getStats());"
```

---

## ğŸ“ˆ Performance

| Jobs | Time Estimate | Notes |
|------|---------------|-------|
| 10 | ~1-2 minutes | Quick test |
| 50 | ~5-10 minutes | Typical workflow |
| 100 | ~10-20 minutes | Large batch |
| 500 | ~1-1.5 hours | Consider splitting |

**Note:** Times assume mixed platforms. Subsequent runs are faster due to caching.

---

## ğŸ› ï¸ Configuration

### Batch Processing (Optional)

Edit `.github/scripts/job-fetcher/job-processor.js`:

```javascript
const jobsWithDescriptions = await fetchDescriptionsBatch(freshJobs, {
    batchSize: 10,              // Adjust for your job volume
    delayBetweenRequests: 1000  // Rate limiting (milliseconds)
});
```

**Recommendations:**
- Small batches (<50 jobs): `batchSize: 10`
- Large batches (>100 jobs): `batchSize: 20`
- Always keep `delayBetweenRequests >= 1000` for respectful scraping

---

## ğŸ› Troubleshooting

### Low Success Rate

**Check:**
1. GitHub Actions logs for specific errors
2. Platform HTML structure changes (update selectors)
3. Network/timeout issues

**Debug:**
```bash
node test-all-platforms.js
```

### Puppeteer Fails in GitHub Actions

**Solution:** Ensure workflow has sufficient timeout:
```yaml
- name: Update Jobs
  timeout-minutes: 60  # Increase if needed
```

### Cache Not Working

**Check:**
```bash
ls -la .github/data/description-cache/
```

**Clear cache:**
```bash
node -e "const {cache}=require('./jobboard/src/backend/services/descriptionFetchers'); cache.clear();"
```

---

## ğŸ“¦ Dependencies

```json
{
  "cheerio": "^1.1.2",      // HTML parsing (HTTP scrapers)
  "puppeteer": "^24.30.0"   // Headless browser (Workday/Lever)
}
```

**Total size:** ~500MB (includes Chromium bundled with Puppeteer)

---

## ğŸ“ File Structure

```
New-Grad-Positions/
â”œâ”€â”€ jobboard/src/backend/services/descriptionFetchers/
â”‚   â”œâ”€â”€ index.js                      # Main orchestrator
â”‚   â”œâ”€â”€ cache.js                      # 7-day caching
â”‚   â”œâ”€â”€ greenhouseFetcher.js         # HTTP scraper
â”‚   â”œâ”€â”€ ashbyFetcher.js              # JSON-LD extractor
â”‚   â”œâ”€â”€ workdayFetcherPuppeteer.js   # Puppeteer for Workday
â”‚   â”œâ”€â”€ leverFetcherPuppeteer.js     # Puppeteer for Lever
â”‚   â”œâ”€â”€ genericFetcher.js            # Fallback
â”‚   â””â”€â”€ README.md                     # Full documentation
â”‚
â”œâ”€â”€ .github/scripts/job-fetcher/
â”‚   â””â”€â”€ job-processor.js             # â† Integration point (modified)
â”‚
â”œâ”€â”€ .github/data/
â”‚   â””â”€â”€ description-cache/           # â† Cache storage (auto-created)
â”‚
â”œâ”€â”€ test-all-platforms.js            # Test suite
â”œâ”€â”€ test-integration.js              # Integration test
â”œâ”€â”€ DESCRIPTION_FETCHER_README.md    # â† This file
â”œâ”€â”€ DESCRIPTION_FETCHER_FINAL_SUMMARY.md
â”œâ”€â”€ INTEGRATION_COMPLETE.md
â””â”€â”€ CHANGELOG.md                      # Version 2.0.0 notes
```

---

## ğŸ” Security & Best Practices

âœ… **Respectful scraping:** 1 second delay between requests
âœ… **Public data only:** No authentication bypass
âœ… **Graceful failures:** Jobs post even if description fetch fails
âœ… **Caching:** Minimizes redundant requests
âœ… **Rate limiting:** Prevents overwhelming job boards
âœ… **Timeout protection:** No infinite hanging

---

## ğŸ“ Next Steps

1. **Monitor first production run**
   - Check GitHub Actions logs for success rates
   - Verify descriptions in Discord posts
   - Review cache creation

2. **Optimize if needed**
   - Adjust batch size based on job volume
   - Update selectors if platforms change
   - Add more platforms as needed

3. **Maintain**
   - Clear expired cache periodically: `cache.clearExpired()`
   - Update dependencies: `npm update`
   - Monitor success rates over time

---

## âœ¨ Success Criteria

You'll know it's working when you see:

âœ… Console output shows "Fetching job descriptions..."
âœ… Success rate ~90% or higher
âœ… Discord posts include full descriptions
âœ… Cache directory populated
âœ… Workflow completes within expected time

---

**Questions?** Check the full documentation:
- Technical details â†’ `DESCRIPTION_FETCHER_FINAL_SUMMARY.md`
- Integration steps â†’ `INTEGRATION_COMPLETE.md`
- API reference â†’ `jobboard/src/backend/services/descriptionFetchers/README.md`
